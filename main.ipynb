{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0276495b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary as summary\n",
    "\n",
    "from Models.CNNmodel import CNN\n",
    "from Models.ResNetmodel import resnet34\n",
    "from DataUtils.load_dataset import QuickDrawDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602ec39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 파라미터\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "num_epochs=30\n",
    "gamma=0.1\n",
    "image_size=28\n",
    "learning_rate=0.1\n",
    "lr_decay_step=[12,20]\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12dfa81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image num: 80000\n",
      "Test image num: 20000\n"
     ]
    }
   ],
   "source": [
    "#훈련데이터\n",
    "train_dataset=QuickDrawDataset(dtype='train')\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "\n",
    "#테스트 데이터\n",
    "test_dataset=QuickDrawDataset(dtype='test')\n",
    "test_loader=DataLoader(dataset=test_dataset,batch_size=64,shuffle=True)\n",
    "\n",
    "num_classes=train_dataset.get_num_classes()\n",
    "\n",
    "print(\"Train image num:\",len(train_dataset))\n",
    "print(\"Test image num:\",len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b6cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyj_0\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hyj_0\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#model=CNN(num_classes).to(DEVICE)\n",
    "model=resnet34(num_classes)\n",
    "#loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate,\n",
    "                         momentum=momentum,weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff01dea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             576\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "              ReLU-3           [-1, 64, 28, 28]               0\n",
      "         MaxPool2d-4           [-1, 64, 14, 14]               0\n",
      "            Conv2d-5           [-1, 64, 14, 14]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 14, 14]             128\n",
      "              ReLU-7           [-1, 64, 14, 14]               0\n",
      "            Conv2d-8           [-1, 64, 14, 14]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 14, 14]             128\n",
      "             ReLU-10           [-1, 64, 14, 14]               0\n",
      "       BasicBlock-11           [-1, 64, 14, 14]               0\n",
      "           Conv2d-12           [-1, 64, 14, 14]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 14, 14]             128\n",
      "             ReLU-14           [-1, 64, 14, 14]               0\n",
      "           Conv2d-15           [-1, 64, 14, 14]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 14, 14]             128\n",
      "             ReLU-17           [-1, 64, 14, 14]               0\n",
      "       BasicBlock-18           [-1, 64, 14, 14]               0\n",
      "           Conv2d-19           [-1, 64, 14, 14]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 14, 14]             128\n",
      "             ReLU-21           [-1, 64, 14, 14]               0\n",
      "           Conv2d-22           [-1, 64, 14, 14]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 14, 14]             128\n",
      "             ReLU-24           [-1, 64, 14, 14]               0\n",
      "       BasicBlock-25           [-1, 64, 14, 14]               0\n",
      "           Conv2d-26            [-1, 128, 7, 7]          73,728\n",
      "      BatchNorm2d-27            [-1, 128, 7, 7]             256\n",
      "             ReLU-28            [-1, 128, 7, 7]               0\n",
      "           Conv2d-29            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-30            [-1, 128, 7, 7]             256\n",
      "           Conv2d-31            [-1, 128, 7, 7]           8,192\n",
      "      BatchNorm2d-32            [-1, 128, 7, 7]             256\n",
      "             ReLU-33            [-1, 128, 7, 7]               0\n",
      "       BasicBlock-34            [-1, 128, 7, 7]               0\n",
      "           Conv2d-35            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-36            [-1, 128, 7, 7]             256\n",
      "             ReLU-37            [-1, 128, 7, 7]               0\n",
      "           Conv2d-38            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-39            [-1, 128, 7, 7]             256\n",
      "             ReLU-40            [-1, 128, 7, 7]               0\n",
      "       BasicBlock-41            [-1, 128, 7, 7]               0\n",
      "           Conv2d-42            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-43            [-1, 128, 7, 7]             256\n",
      "             ReLU-44            [-1, 128, 7, 7]               0\n",
      "           Conv2d-45            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-46            [-1, 128, 7, 7]             256\n",
      "             ReLU-47            [-1, 128, 7, 7]               0\n",
      "       BasicBlock-48            [-1, 128, 7, 7]               0\n",
      "           Conv2d-49            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-50            [-1, 128, 7, 7]             256\n",
      "             ReLU-51            [-1, 128, 7, 7]               0\n",
      "           Conv2d-52            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 7, 7]             256\n",
      "             ReLU-54            [-1, 128, 7, 7]               0\n",
      "       BasicBlock-55            [-1, 128, 7, 7]               0\n",
      "           Conv2d-56            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 4, 4]             512\n",
      "             ReLU-58            [-1, 256, 4, 4]               0\n",
      "           Conv2d-59            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 4, 4]             512\n",
      "           Conv2d-61            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 4, 4]             512\n",
      "             ReLU-63            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-64            [-1, 256, 4, 4]               0\n",
      "           Conv2d-65            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 4, 4]             512\n",
      "             ReLU-67            [-1, 256, 4, 4]               0\n",
      "           Conv2d-68            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 4, 4]             512\n",
      "             ReLU-70            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-71            [-1, 256, 4, 4]               0\n",
      "           Conv2d-72            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 4, 4]             512\n",
      "             ReLU-74            [-1, 256, 4, 4]               0\n",
      "           Conv2d-75            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 4, 4]             512\n",
      "             ReLU-77            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-78            [-1, 256, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 4, 4]             512\n",
      "             ReLU-84            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-85            [-1, 256, 4, 4]               0\n",
      "           Conv2d-86            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 4, 4]             512\n",
      "             ReLU-88            [-1, 256, 4, 4]               0\n",
      "           Conv2d-89            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 4, 4]             512\n",
      "             ReLU-91            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-92            [-1, 256, 4, 4]               0\n",
      "           Conv2d-93            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 4, 4]             512\n",
      "             ReLU-95            [-1, 256, 4, 4]               0\n",
      "           Conv2d-96            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 4, 4]             512\n",
      "             ReLU-98            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-99            [-1, 256, 4, 4]               0\n",
      "          Conv2d-100            [-1, 512, 2, 2]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-102            [-1, 512, 2, 2]               0\n",
      "          Conv2d-103            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 2, 2]           1,024\n",
      "          Conv2d-105            [-1, 512, 2, 2]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "      BasicBlock-108            [-1, 512, 2, 2]               0\n",
      "          Conv2d-109            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-111            [-1, 512, 2, 2]               0\n",
      "          Conv2d-112            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-114            [-1, 512, 2, 2]               0\n",
      "      BasicBlock-115            [-1, 512, 2, 2]               0\n",
      "          Conv2d-116            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-118            [-1, 512, 2, 2]               0\n",
      "          Conv2d-119            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-121            [-1, 512, 2, 2]               0\n",
      "      BasicBlock-122            [-1, 512, 2, 2]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                   [-1, 20]          10,260\n",
      "================================================================\n",
      "Total params: 21,286,100\n",
      "Trainable params: 21,286,100\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 6.43\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 87.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d316c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=0.0\n",
    "train_accuracy=0.0\n",
    "test_loss=0.0\n",
    "test_accuracy=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6c3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global train_loss\n",
    "    global train_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    loss_avg=0.0\n",
    "    correct=0\n",
    "    data_loader=tqdm(train_loader,desc='Training')\n",
    "\n",
    "    for batch_idx,(data,target) in enumerate(data_loader):\n",
    "        data,target=torch.autograd.Variable(data.cpu()),torch.autograd.Variable(target.cpu())\n",
    "\n",
    "        data=data.view(-1,1,28,28)\n",
    "        data/=255.0\n",
    "\n",
    "        output=model(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss=F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred=output.data.max(1)[1]\n",
    "        correct=correct+float(pred.eq(target.data).sum())\n",
    "        loss_avg=loss_avg*0.2+float(loss)*0.8\n",
    "            \n",
    "    train_loss=loss_avg\n",
    "    train_accuracy=correct/len(train_loader.dataset)\n",
    "    print(correct,\"a:\",train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae1ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    global test_loss\n",
    "    global test_accuracy\n",
    "    model.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    data_loader=tqdm(test_loader,desc='Testing')\n",
    "\n",
    "    for batch_idx,(data,target) in enumerate(data_loader):\n",
    "        data,target=torch.autograd.Variable(data.cpu()),torch.autograd.Variable(target.cpu())\n",
    "\n",
    "        data=data.view(-1,1,28,28)\n",
    "        data/=255.0\n",
    "\n",
    "        output=model(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss=F.cross_entropy(output,target)\n",
    "\n",
    "        pred=output.data.max(1)[1]\n",
    "        correct=correct+float(pred.eq(target.data).sum())\n",
    "        \n",
    "        \n",
    "\n",
    "        loss_avg=loss_avg+float(loss)\n",
    "\n",
    "    test_loss=loss_avg/len(test_loader)\n",
    "    test_accuracy=correct/len(test_loader.dataset)\n",
    "    print(correct,\"a:\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53638e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 is running...\n",
      "current epoch: 1\n",
      "TRAIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|██████████████████████████████████████████████████████████████████▏   | 296/313 [28:02<01:35,  5.60s/it]"
     ]
    }
   ],
   "source": [
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch \"+str(epoch+1)+\" is running...\")\n",
    "    if epoch+1 in lr_decay_step:\n",
    "        learning_rate=learning_rate*gamma\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr']=learning_rate\n",
    "            \n",
    "    current_epoch=epoch+1\n",
    "    print(\"current epoch:\",current_epoch)\n",
    "    print(\"TRAIN\")\n",
    "    train()\n",
    "    print(\"TEST\")\n",
    "    test()\n",
    "    print(\"test accuracy:\",test_accuracy)\n",
    "    \n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy=test_accuracy\n",
    "        torch.save(model.state_dict(),os.path.join(\"./\",'model.pytorch'))\n",
    "        \n",
    "    print('Best Accuracy: %.4f' %best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
